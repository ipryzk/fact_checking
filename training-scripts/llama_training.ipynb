{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# File paths\n",
    "data_file = 'dataset/processed_llama_output.jsonl'  # path to your JSONL file\n",
    "train_file = 'dataset/train/train_data.jsonl'\n",
    "val_file = 'dataset/val/val_data.jsonl'\n",
    "\n",
    "# Step 1: Load the data from the JSONL file\n",
    "with open(data_file, 'r') as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "# Step 2: Shuffle the data to ensure random distribution\n",
    "random.shuffle(data)\n",
    "\n",
    "# Step 3: Calculate the split sizes\n",
    "train_size = int(len(data) * 0.8)\n",
    "val_size = int(len(data) * 0.2)\n",
    "\n",
    "# Step 4: Split the data into train, validation, and test sets\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:train_size + val_size]\n",
    "\n",
    "# Step 5: Save the splits into separate JSONL files\n",
    "def save_jsonl(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "save_jsonl(train_data, train_file)\n",
    "save_jsonl(val_data, val_file)\n",
    "\n",
    "print(f\"Data split into train, validation, and test sets.\")\n",
    "print(f\"Train set: {train_size} records\")\n",
    "print(f\"Validation set: {val_size} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Set paths to the model, train, validation and test sets.\n",
    "MODEL=\"./llama-3_1-8b-instruct-nemo_v1.0/llama3_1_8b_instruct.nemo\"\n",
    "\n",
    "TRAIN_DS=\"[dataset/train/train_data.jsonl]\"\n",
    "VALID_DS=\"[dataset/val/val_data.jsonl]\"\n",
    "TEST_DS=\"[dataset/test/test_data.jsonl]\"\n",
    "TEST_NAMES=\"[factcheck]\"\n",
    "SCHEME=\"lora\"\n",
    "TP_SIZE=1\n",
    "PP_SIZE=1\n",
    "\n",
    "rm -rf results\n",
    "OUTPUT_DIR=\"./results/Meta-llama3.1-8B-Instruct-factgen\"\n",
    "\n",
    "torchrun --nproc_per_node=1 \\\n",
    "/opt/NeMo/examples/nlp/language_modeling/tuning/megatron_gpt_finetuning.py \\\n",
    "    exp_manager.exp_dir=${OUTPUT_DIR} \\\n",
    "    exp_manager.explicit_log_dir=${OUTPUT_DIR} \\\n",
    "    trainer.devices=1 \\\n",
    "    trainer.num_nodes=1 \\\n",
    "    trainer.precision=bf16-mixed \\\n",
    "    trainer.val_check_interval=0.2 \\\n",
    "    trainer.max_steps=900 \\\n",
    "    model.megatron_amp_O2=True \\\n",
    "    ++model.mcore_gpt=True \\\n",
    "    model.tensor_model_parallel_size=${TP_SIZE} \\\n",
    "    model.pipeline_model_parallel_size=${PP_SIZE} \\\n",
    "    model.micro_batch_size=1 \\\n",
    "    model.global_batch_size=32 \\\n",
    "    model.restore_from_path=${MODEL} \\\n",
    "    model.data.train_ds.file_names=${TRAIN_DS} \\\n",
    "    model.data.train_ds.concat_sampling_probabilities=[1.0] \\\n",
    "    model.data.validation_ds.file_names=${VALID_DS} \\\n",
    "    model.peft.peft_scheme=${SCHEME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull your server to test deployment (I personally used NIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE OUTPUT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "url = 'your-host-url'\n",
    "headers = {\n",
    "    'accept': 'application/json',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# Example from the test set\n",
    "prompt= \"\"\"\n",
    "        Task: Contrast the claim using the given text. \n",
    "        Claim: Mindfulness in education will universally improve academic scores. \n",
    "        [SEP] Text: Figure 1 summarizes the study design and the numbers of students assessed at each time point. Table 1 Demographics of intervention and control cohortFull size \n",
    "        tableConfirmation of reliability and validity of the questionnairesThe reliability and validity of the perceived stress (PSS-10) and and Awareness (MAAS) \n",
    "        Scales were confirmed by using all data sates that were returned to us (T1: n = 139, T3: n = 148). Internal consistencies were assessed by calculating \n",
    "        Cronbach\\u2019s alpha for both scales (PSS and MAAS) and both time points. The resulting values ranged between 0. 851 and 0. 914 and thus proved reliable. \n",
    "        Validities were confirmed via confirmatory factor analyses and the results also showed a good fit (additional Table 1[see additional file 1]). Further descriptive statistics \n",
    "        for the questionnaires are provided in the additional Tables 2\\u20135 [see additional file 1]. Mindfulness and perceived stress were inversely correlated. Our longitudinal analysis \n",
    "        of medical students over their first and third term revealed, that elevated mindfulness was paralleled by a reduction of perceived stress and vice versa. \n",
    "        Spearman rank correlation analyses performed for our study cohort revealed statistically significant correlations with coefficients of r = \\u2212 0. 4594 at T1 \n",
    "        (95% CI = \\u2212 0. 5831 to \\u2212 0. 3149, p < 0. 0001) and r = \\u2212 0. 5300 at T3 (95% CI = \\u2212 0. 6552 to \\u2212 0. 3764, p < 0. 0001) (Fig. 2).\n",
    "        Neither mindfulness nor perceived stress correlated with academic achievements in the first year at medical schoolWe here assessed whether mindfulness or \n",
    "        perceived stress were associated with exam results in first year medical students and therefore correlated the exam scores achieved at T1 with the scores obtained from the \n",
    "        simultaneously assessed stress and mindfulness scales, respectively. While there were no correlations between mindfulness and exam scores, there was a \n",
    "        negligible correlation between perceived stress and the results from the biology exam that yielded in a correlation coefficient of 0. 177 and a p-value of 0. 0456.\n",
    "        The improvement of academic achievements following an intervention on MBSR was transientIn order to analyze whether our intervention teaching formal techniques of \n",
    "        MBSR impacted positively on the academic performance, we compared exam results between intervention and control cohorts. [SEP] JUSTIFY:\n",
    "\"\"\"\n",
    "data = {\n",
    "    \"model\": \"your fact-checking path\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 500\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "response_data = response.json()\n",
    "\n",
    "print(f\"OUTPUT: {response_data['choices'][0]['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE OUTPUT: The text contrasts the claim by providing evidence that mindfulness in medical education did not correlate with academic achievements for first-year medical students. It states that while elevated mindfulness was associated with a reduction in perceived stress, it found no correlation with academic achievements, thereby challenging the idea that mindfulness leads to universally improved grades."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
